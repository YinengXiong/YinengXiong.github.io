---
layout:     post
title:      "AdaIN for Arbitary Style Transfer"
date:       2020-09-17
author:     "Yineng Xiong"
header-img: "img/2020-09-17/banner.png"
tags:
    - Deep Learning
    - Style Transfer
    - Adaptive Instance Normalization
---

> 希望这不是今年的唯一一篇Blog

## Style Transfer

用神经网络做`Style Transfer`这个任务是`Gatys`等最先提出的。初代的`Style Transfer`需要随机初始化图片，**把图片当做可以训练的变量**，通过优化`Content Loss`和`Style Loss`来得到内容上与`Content Image`接近，风格上与`Style Image`接近的图像。这种形式属于固定风格固定内容的风格迁移

如何衡量生成图片与`Content Image`、`Style Image`的内容和风格的相似程度？首先是内容差异，将图像通过一个CNN（VGG），通过某一层输出的特征图来衡量图片的内容差异。风格差异是通过**Gram矩阵**来对风格进行数学表示，**Gram矩阵**实际上可看做是features之间的偏心协方差矩阵，将图片经过一个CNN(VGG)，将其中的某(些)层 $l$ 的特征图 $F$，那么**Gram矩阵**可以表示为：

<center>$G[i, j] = \sum \sum F_i{[x, y]}\cdot{F_j{[x, y]}}$</center>

那么`Content Loss`就是输出和`Content Image`经过VGG后的某一层的Feature，`Style Loss`就是输出和`Style Image`经过VGG后Feature的**Gram矩阵**。

这种方法每一个Content-Style Pair都需要优化很长时间，`Ulyanov`等用一个神经网络替代优化的过程，也就是用了一个generator来生成，在这个generator里用了`BN`

然后他们又发现，把BN换成`Instance Norm`(IN)可以提升收敛速度，这俩的区别就在于BN是在一个Batch内统计的，而IN是单张图片统计的。

随后，Dumoulin等发现进行IN的时候，使用不同的 $\gamma$ 和 $\beta$ 就可以生成出不同风格的图像，一种风格对应一组 $(\gamma^i, \beta^i)$，于是就有了`Conditional Instance Normalization`
<center>$CIN(x; i) = \gamma^i (\frac{x - \mu(x)}{\sigma(x)}) + \beta^i$</center>

这种方法可以进行有限风格的迁移，每一个Style都需要训练一个新的模型。

在这个思想的基础上就有了`Adaptive Instance Normalization`也就是AdaIN，直接用一张图片算出 $\gamma$ 和 $\beta$，作用在另一张图像上，就可以实现任意风格的迁移。

<center>$AdaIN(x, y) = \sigma^y (\frac{x - \mu(x)}{\sigma(x)}) + \mu^y$</center>

## Model

模型其实就很简单了，把Content和Style经过VGG后做AdaIN，最后通过一个Decoder来得到output。Decoder输出的结果再通过VGG来得到`Content Loss`和`Style Loss`
![model](https://raw.githubusercontent.com/YinengXiong/YinengXiong.github.io/master/img/2020-09-17/model.png)

`Content Loss`还是常规的feature map的MSELoss，`Style Loss`这里变成了Decoder生成结果经过VGG后feature map的均值和方差做MSELoss，而不是**Gram矩阵**

<img src="https://raw.githubusercontent.com/YinengXiong/YinengXiong.github.io/master/img/2020-09-17/styleloss.png" width="400px"/>

## Training

训练就按照Paper上描述的，Content数据集用[MS COCO](https://cocodataset.org/#download)，Style数据集用的[WikiArt](https://www.kaggle.com/c/painter-by-numbers/data)，`COCO`大概又11W张，`WikiArt`接近8W张。先resize到短边512，random crop到256训练，大概25个Epoch，`Content Loss`，`Style Loss`的weight和paper一致。

## Results
直接上图

![img1](https://raw.githubusercontent.com/YinengXiong/YinengXiong.github.io/master/img/2020-09-17/0013_antimonocromatismo_style_transfer_demo.png)
![img2](https://raw.githubusercontent.com/YinengXiong/YinengXiong.github.io/master/img/2020-09-17/0013_asheville_style_transfer_demo.png)

![img3](https://raw.githubusercontent.com/YinengXiong/YinengXiong.github.io/master/img/2020-09-17/1454_hosi_style_transfer_demo.png)
![img4](https://raw.githubusercontent.com/YinengXiong/YinengXiong.github.io/master/img/2020-09-17/1454_la_muse_style_transfer_demo.png)

![img5](https://raw.githubusercontent.com/YinengXiong/YinengXiong.github.io/master/img/2020-09-17/0003_mondrian_style_transfer_demo.png)
![img6](https://raw.githubusercontent.com/YinengXiong/YinengXiong.github.io/master/img/2020-09-17/0003_sketch_style_transfer_demo.png)

![img7](https://raw.githubusercontent.com/YinengXiong/YinengXiong.github.io/master/img/2020-09-17/2984_picasso_self_portrait_style_transfer_demo.png)
![img8](https://raw.githubusercontent.com/YinengXiong/YinengXiong.github.io/master/img/2020-09-17/2984_trial_style_transfer_demo.png)

![img9](https://raw.githubusercontent.com/YinengXiong/YinengXiong.github.io/master/img/2020-09-17/2912_scene_de_rue_style_transfer_demo.png)
![img10](https://raw.githubusercontent.com/YinengXiong/YinengXiong.github.io/master/img/2020-09-17/2912_en_campo_gris_style_transfer_demo.png)

## Style Interpolation

除了做Style Transfer之外，AdaIN还可以做Style Interpolation，把Style从弱到强过渡：

```Python
t = adain(content_features, style_features)
t = alpha * t + (1 - alpha) * content_features
out = Decoder(t)
```

放两张结果，从上到下从左到右分别为：**Content Image, $\alpha=0.25$, $\alpha=0.5$, $\alpha=0.75$, $\alpha=1$, Style Image**

![img11](https://raw.githubusercontent.com/YinengXiong/YinengXiong.github.io/master/img/2020-09-17/0003_mondrian_sytle_interpolate_demo.jpg)
![img12](https://raw.githubusercontent.com/YinengXiong/YinengXiong.github.io/master/img/2020-09-17/0003_sketch_sytle_interpolate_demo.jpg)

## Next
下篇争取国庆节妈的